{"paragraphs":[{"text":"//Problem A\n/*\nPrint out all words that appear between 5 and 7 times (including 5 and 7) in the wap.txt\ndocument. The words can appear in any order. Print out only the words and not the\nassociated count. All words are separated by whitespace (spaces, tabs, newlines) only.\nAll other characters belong to a word. For example, don’t is a word and hello, is a word\n(note the comma) which is different from the word hello that might appear in the\ndocument. A word must contain at least 1 character (i.e. the empty string is ignored for\nall problems). The words should be case-insensitive: the and The are the same word.\n*/\n\nsc.setLogLevel(\"WARN\")\nval lineList = sc.textFile(\"/user/zeppelin/wap.txt\")\n\nval wordList = lineList.flatMap(line => line.split(\" \"))\n\nval filteredWordList = wordList.filter(word => word.length()>0)\n\nval lowerWordList = filteredWordList.map(word => word.toLowerCase())\n\nval wordCountList = lowerWordList.map(word => (word, 1)).reduceByKey((a,b) => a+b)\n\nval filteredWordCountList = wordCountList.filter{case (key, value) => value >=5 && value <=7}\n\nval allWords = filteredWordCountList.keys\nallWords.collect()\n","user":"anonymous","dateUpdated":"2020-11-17T02:45:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lineList: org.apache.spark.rdd.RDD[String] = /user/zeppelin/wap.txt MapPartitionsRDD[183] at textFile at <console>:28\nwordList: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[184] at flatMap at <console>:29\nfilteredWordList: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[185] at filter at <console>:29\nlowerWordList: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[186] at map at <console>:29\nwordCountList: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[188] at reduceByKey at <console>:29\nfilteredWordCountList: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[189] at filter at <console>:29\nallWords: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[190] at keys at <console>:29\nres268: Array[String] = Array(blandly, contemptible, thee,, seventy, beekeeper, pale., unchanging, german., demanded., servants,, canteen, thickly, entrance,, interfere, nowadays, “never, deceased, trial, arakchéev’s, seem,, blown, tossed, naïvely, tact, “here,, very,, “two, escort,, namely,, kochubéy, depicted, say?, remark,, liberated, “eh?, throng, birds, biscuits, previously,, hinted, monarch, refuge, princes, call., huddled, excellency., dmítrich, sufferings,, dignity,, heeding, mílka, hurrah, weren’t, november,, “count!, baby., ourselves,, victories, twisted, 1807, governed, grandeur, owners, distressed, jesus, temples,, disclosed, vexation., tree,, imagination., postmaster, yourself.”, berg’s, effort., talleyrand,, palace,, maids,, once,”, calf, rapid,, surprising, inspire, spot...."}]},"apps":[],"jobName":"paragraph_1605544089877_998048338","id":"20201116-162809_1059532675","dateCreated":"2020-11-16T16:28:09+0000","dateStarted":"2020-11-17T02:45:29+0000","dateFinished":"2020-11-17T02:45:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:354"},{"text":"//Problem B\n/*\nConsider the complete taxi dataset that you downloaded in step 2a. Which grouping of\nfares tips the best? The fare groups you should consider are this: $0 - $24.99, $25 -\n$49.99, $50 - $74.99, $75+. When considering the best tip, you should consider the tip\nas a percentage of the fare. You should sum up the total tips for each group and divide\nit by the total fares for each group to get the percentage. Print out each grouping along\nwith it’s tip percentage. Do not do any rounding.\n*/\n\n// VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,RatecodeID,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\n// 2,2016-06-09 21:06:36,2016-06-09 21:13:08,2,.79,-73.983360290527344,40.760936737060547,1,N,-73.977462768554688,40.753978729248047,2,6,0.5,0.5,0,0,0.3,7.3\n// 2,2016-06-09 21:06:36,2016-06-09 21:35:11,1,5.22,-73.981719970703125,40.736667633056641,1,N,-73.981636047363281,40.670242309570313,1,22,0.5,0.5,4,0,0.3,27.3\n// 2,2016-06-09 21:06:36,2016-06-09 21:13:10,1,1.26,-73.994316101074219,40.751071929931641,1,N,-74.004234313964844,40.742168426513672,1,6.5,0.5,0.5,1.56,0,0.3,9.36\n// 2,2016-06-09 21:06:36,2016-06-09 21:36:10,1,7.39,-73.98236083984375,40.773891448974609,1,N,-73.929466247558594,40.851539611816406,1,26,0.5,0.5,1,0,0.3,28.3\n\n\nsc.setLogLevel(\"WARN\")\n\nval taxi = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\",true).load(\"/user/zeppelin/taxi.csv\").select($\"fare_amount\", $\"tip_amount\")\n\n\nval withFairGroup = taxi.withColumn(\"fairGroup\", \n    when(col(\"fare_amount\") >= 75.00, \"$75+\")\n    .when(col(\"fare_amount\") >= 50.00, \"$50 - $74.99\")\n    .when(col(\"fare_amount\") >= 25.00, \"$25 - $49.99\")\n    .otherwise(\"$0 - $24.99\")\n    )\n\nwithFairGroup.createOrReplaceTempView(\"taxiView\")\n\nval output = spark.sqlContext.sql(\"SELECT fairGroup, SUM(tip_amount)/SUM(fare_amount)*100 AS tipPercentage FROM taxiView GROUP BY fairGroup ORDER BY fairGroup\")\noutput.show()\n\n","user":"anonymous","dateUpdated":"2020-11-17T02:45:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"taxi: org.apache.spark.sql.DataFrame = [fare_amount: double, tip_amount: double]\nwithFairGroup: org.apache.spark.sql.DataFrame = [fare_amount: double, tip_amount: double ... 1 more field]\noutput: org.apache.spark.sql.DataFrame = [fairGroup: string, tipPercentage: double]\n+------------+------------------+\n|   fairGroup|     tipPercentage|\n+------------+------------------+\n| $0 - $24.99| 13.71537181009071|\n|$25 - $49.99| 14.52681632879384|\n|$50 - $74.99|13.360785323091612|\n|        $75+| 6.482628978707234|\n+------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1605544121520_-1075886152","id":"20201116-162841_442434269","dateCreated":"2020-11-16T16:28:41+0000","dateStarted":"2020-11-17T02:45:29+0000","dateFinished":"2020-11-17T02:50:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:355"},{"text":"//Problem C\n/*\nConsider the complete taxi dataset that you downloaded in step 2a. What were the top\n10 (fare_amount / trip_distance) rows? In other words, what trips cost the most for the\nleast amount of distance traveled? For this problem, you should not consider any\ntrip_distances with a value of 0 as all of them would have an infinite fare to distance\nratio. Also do not consider any negative trip_distances. Print your answer in order by\nrank (i.e. all rank 1’s first, then all rank 2’s, etc.). If there are ties, use the dense rank\nthat we’ve used in previous activities. Only print out the (fare_amount / trip_distance)\nanswer with its corresponding rank.\n*/\n\n// VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,RatecodeID,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\n// 2,2016-06-09 21:06:36,2016-06-09 21:13:08,2,.79,-73.983360290527344,40.760936737060547,1,N,-73.977462768554688,40.753978729248047,2,6,0.5,0.5,0,0,0.3,7.3\n// 2,2016-06-09 21:06:36,2016-06-09 21:35:11,1,5.22,-73.981719970703125,40.736667633056641,1,N,-73.981636047363281,40.670242309570313,1,22,0.5,0.5,4,0,0.3,27.3\n// 2,2016-06-09 21:06:36,2016-06-09 21:13:10,1,1.26,-73.994316101074219,40.751071929931641,1,N,-74.004234313964844,40.742168426513672,1,6.5,0.5,0.5,1.56,0,0.3,9.36\n// 2,2016-06-09 21:06:36,2016-06-09 21:36:10,1,7.39,-73.98236083984375,40.773891448974609,1,N,-73.929466247558594,40.851539611816406,1,26,0.5,0.5,1,0,0.3,28.3\n\nsc.setLogLevel(\"WARN\")\nimport org.apache.spark.sql.expressions._\n\nval taxiC = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\",true).load(\"/user/zeppelin/taxi.csv\").select($\"fare_amount\", $\"trip_distance\")\n\nval windowSpec = Window.orderBy($\"costPerDistance\".desc)\n\nval taxiC2 = taxiC.filter(col(\"trip_distance\")>0).withColumn(\"costPerDistance\", col(\"fare_amount\")/col(\"trip_distance\"))\n\nval taxiC3 = taxiC2.withColumn(\"dense_rank\", dense_rank().over(windowSpec))\n\ntaxiC3.createOrReplaceTempView(\"taxiViewC\")\n\nval output = spark.sqlContext.sql(\"SELECT costPerDistance, dense_rank FROM taxiViewC where dense_rank<=10 ORDER BY dense_rank\")\noutput.show()\n\n\n\n","user":"anonymous","dateUpdated":"2020-11-17T03:17:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions._\ntaxiC: org.apache.spark.sql.DataFrame = [fare_amount: double, trip_distance: double]\nwindowSpec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@5cea9a0e\ntaxiC2: org.apache.spark.sql.DataFrame = [fare_amount: double, trip_distance: double ... 1 more field]\ntaxiC3: org.apache.spark.sql.DataFrame = [fare_amount: double, trip_distance: double ... 2 more fields]\noutput: org.apache.spark.sql.DataFrame = [costPerDistance: double, dense_rank: int]\n+------------------+----------+\n|   costPerDistance|dense_rank|\n+------------------+----------+\n|104133.86666666665|         1|\n|           35000.0|         2|\n|           24800.0|         3|\n|           21130.0|         4|\n|           20000.0|         5|\n|           20000.0|         5|\n|           19500.0|         6|\n|           17500.0|         7|\n|           16788.0|         8|\n|           15000.0|         9|\n|           15000.0|         9|\n|           15000.0|         9|\n|           14800.0|        10|\n+------------------+----------+\n\n"}]},"apps":[],"jobName":"paragraph_1605574856803_245955365","id":"20201117-010056_57603579","dateCreated":"2020-11-17T01:00:56+0000","dateStarted":"2020-11-17T03:17:37+0000","dateFinished":"2020-11-17T03:22:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:356"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1605582624819_1394038016","id":"20201117-031024_1453940941","dateCreated":"2020-11-17T03:10:24+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:690"}],"name":"ActivitySix","id":"2FQHDZW3Y","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}