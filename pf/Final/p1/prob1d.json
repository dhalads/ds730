{"paragraphs":[{"text":"//Problem 1d\n\n/*\nSolve this problem for Oshkosh only. For each day in the input file (e.g.\nFebruary 1, 2004, May 11, 2010, January 29, 2007), determine the coldest\ntime for that day. The coldest time for any given day is defined as the\nhour(s) that has/have the coldest average. For example, a day may have\nhad two readings during the 4am hour, one at 4:15am and one at 4:45am.\nThe temperatures may have been 10.5 and 15.3. The average for 4am is\n12.9. The 5am hour for that day may have had two readings at 5:14am\nand 5:35am and those readings were 11.3 and 11.5. The average for 5am\nis 11.4. 5am is thus considered colder. If multiple hours have the same\ncoldest average temperature on any given day, then those hours that have\nthe coldest average are all considered the coldest for that day. Once you\nhave determined the coldest hour for each day, return the hour that has\nthe highest frequency. This is not a windowing problem. You only need to\nconsider the 24 “hours” of the day, i.e. 12am, 1am, 2am, etc.\n*/\n\n/*\nYear,Month,Day,TimeCST,TemperatureF,Dew PointF,Humidity,Sea Level PressureIn,VisibilityMPH,Wind Direction,Wind SpeedMPH,Gust SpeedMPH,PrecipitationIn,Events,Conditions,WindDirDegrees\n2000,1,1,12:53 AM,36,30.9,82,29.95,10,SSW,11.5,-,N/A,,Partly Cloudy,200\n2000,1,1,1:53 AM,37,30.9,79,29.96,10,SSW,6.9,-,N/A,,Partly Cloudy,210\n2000,1,1,2:53 AM,36,30,79,29.96,10,SW,5.8,-,N/A,,Partly Cloudy,220\n2000,1,1,3:53 AM,34,28.9,82,29.96,10,Calm,Calm,-,N/A,,Clear,0\n2000,1,1,4:53 AM,28.9,26.1,89,29.97,10,Calm,Calm,-,N/A,,Partly Cloudy,0\n*/\nimport org.apache.spark.sql.expressions._\n\nval weatherW = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\",true).load(\"/user/maria_dev/final/Oshkosh/OshkoshWeather.csv\"\n    ).filter($\"TemperatureF\" > -100 ).select(\"Year\", \"Month\", \"Day\",\"TimeCST\", \"TemperatureF\")\n\nval extraW = weatherW.withColumn(\"dateString\", \n    concat($\"Year\", lit(\"-\"), format_string(\"%02d\", $\"Month\"), lit(\"-\"), format_string(\"%02d\", $\"Day\"), lit(\" \"), $\"TimeCST\"  )\n    ).withColumn(\"totalSeconds\", \n    unix_timestamp($\"dateString\", \"yyyy-MM-dd h:mm a\")\n    ).withColumn(\"Hour\", \n    from_unixtime($\"totalSeconds\",\"HH\") cast \"Int\"\n    )\n\nval windowSpec2 = Window.partitionBy(\"Year\", \"Month\", \"Day\").orderBy(\"avgTemp\")\n\nval extraW2 = extraW.groupBy(\"Year\", \"Month\", \"Day\", \"Hour\").agg(avg(\"TemperatureF\").as(\"avgTemp\")\n).orderBy(\"Year\", \"Month\", \"Day\", \"Hour\"\n).withColumn(\"dense_rank\", dense_rank().over(windowSpec2)\n).filter($\"dense_rank\" <=1\n).orderBy(\"Year\", \"Month\", \"Day\")\n\nextraW2.show(40, false)\n\nval answer = extraW2.groupBy(\"Hour\").agg(count(\"avgTemp\").as(\"daysColdestHour\")).orderBy($\"daysColdestHour\".desc)\nanswer.select(\"Hour\").limit(1).show(24, false)\n","user":"anonymous","dateUpdated":"2020-12-15T23:26:00+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions._\nweatherW: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 3 more fields]\nextraW: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 6 more fields]\nwindowSpec2: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@1b701c1f\nextraW2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 4 more fields]\n+----+-----+---+----+------------------+----------+\n|Year|Month|Day|Hour|avgTemp           |dense_rank|\n+----+-----+---+----+------------------+----------+\n|2000|1    |1  |8   |28.0              |1         |\n|2000|1    |1  |6   |28.0              |1         |\n|2000|1    |1  |7   |28.0              |1         |\n|2000|1    |2  |23  |30.0              |1         |\n|2000|1    |3  |23  |23.0              |1         |\n|2000|1    |4  |21  |16.0              |1         |\n|2000|1    |5  |7   |5.0               |1         |\n|2000|1    |6  |20  |19.9              |1         |\n|2000|1    |6  |21  |19.9              |1         |\n|2000|1    |7  |7   |7.0               |1         |\n|2000|1    |8  |23  |21.9              |1         |\n|2000|1    |9  |4   |21.1              |1         |\n|2000|1    |10 |18  |32.0              |1         |\n|2000|1    |11 |23  |15.1              |1         |\n|2000|1    |12 |9   |12.16             |1         |\n|2000|1    |13 |23  |6.1               |1         |\n|2000|1    |14 |5   |-0.9              |1         |\n|2000|1    |15 |1   |23.0              |1         |\n|2000|1    |15 |0   |23.0              |1         |\n|2000|1    |15 |4   |23.0              |1         |\n|2000|1    |15 |2   |23.0              |1         |\n|2000|1    |16 |20  |10.0              |1         |\n|2000|1    |17 |0   |12.433333333333332|1         |\n|2000|1    |18 |23  |12.0              |1         |\n|2000|1    |19 |2   |3.9               |1         |\n|2000|1    |20 |23  |-6.0              |1         |\n|2000|1    |21 |6   |-9.9              |1         |\n|2000|1    |22 |0   |5.0               |1         |\n|2000|1    |22 |1   |5.0               |1         |\n|2000|1    |23 |23  |-2.9              |1         |\n|2000|1    |24 |6   |-5.1              |1         |\n|2000|1    |25 |21  |7.0               |1         |\n|2000|1    |25 |22  |7.0               |1         |\n|2000|1    |25 |23  |7.0               |1         |\n|2000|1    |26 |23  |1.0               |1         |\n|2000|1    |27 |5   |-0.9              |1         |\n|2000|1    |27 |3   |-0.9              |1         |\n|2000|1    |27 |2   |-0.9              |1         |\n|2000|1    |27 |6   |-0.9              |1         |\n|2000|1    |27 |4   |-0.9              |1         |\n+----+-----+---+----+------------------+----------+\nonly showing top 40 rows\n\nanswer: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Hour: int, daysColdestHour: bigint]\n+----+\n|Hour|\n+----+\n|5   |\n+----+\n\n"}]},"apps":[],"jobName":"paragraph_1608074674138_2142061679","id":"20201215-232434_1553968273","dateCreated":"2020-12-15T23:24:34+0000","dateStarted":"2020-12-15T23:26:00+0000","dateFinished":"2020-12-15T23:26:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:13358"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1608074760580_543753451","id":"20201215-232600_944089108","dateCreated":"2020-12-15T23:26:00+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:13359"}],"name":"prob1d","id":"2FSKSP7HZ","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}