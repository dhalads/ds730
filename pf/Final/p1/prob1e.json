{"paragraphs":[{"text":"//Problem 1e\n\n/*\nWhich city had a time period of 24 hours or less that saw the largest\ntemperature difference? Report the city, the temperature difference and\nthe minimum amount of time it took to obtain that difference. Do not only\nconsider whole days for this problem. The largest temperature difference\nmay have been from 3pm on a Tuesday to 3pm on a Wednesday. The\nlargest temperature difference could have been from 11:07am on a\nTuesday to 4:03am on a Wednesday. Or the largest difference could have\nbeen from 3:06pm on a Wednesday to 7:56pm on that same Wednesday.\nFor a concrete example, consider Iowa City on January 1, 2000 at 2:53pm\nthrough January 2, 2000 at 2:53pm. The maximum temperature in that 24\nhour span was 54 and the minimum temperature in that 24 hour span was\n36. Therefore, in that 24 hour span, the largest temperature difference\nwas 18 degrees. If this were the final answer, you would output “Iowa\nCity”, “18 degrees” and January 2, 2000 3:53am to January 2, 2000\n10:53am.\n*/\n\n/*\nYear,Month,Day,TimeCST,TemperatureF,Dew PointF,Humidity,Sea Level PressureIn,VisibilityMPH,Wind Direction,Wind SpeedMPH,Gust SpeedMPH,PrecipitationIn,Events,Conditions,WindDirDegrees\n2000,1,1,12:53 AM,36,30.9,82,29.95,10,SSW,11.5,-,N/A,,Partly Cloudy,200\n2000,1,1,1:53 AM,37,30.9,79,29.96,10,SSW,6.9,-,N/A,,Partly Cloudy,210\n2000,1,1,2:53 AM,36,30,79,29.96,10,SW,5.8,-,N/A,,Partly Cloudy,220\n2000,1,1,3:53 AM,34,28.9,82,29.96,10,Calm,Calm,-,N/A,,Clear,0\n2000,1,1,4:53 AM,28.9,26.1,89,29.97,10,Calm,Calm,-,N/A,,Partly Cloudy,0\n*/\nimport org.apache.spark.sql.expressions._\n\nval weatherW = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\",true).load(\"/user/maria_dev/final/Oshkosh/OshkoshWeather.csv\"\n    ).filter($\"TemperatureF\" > -100 ).select(\"Year\", \"Month\", \"Day\",\"TimeCST\", \"TemperatureF\")\n\nval weatherI = spark.read.format(\"csv\").option(\"header\", true).option(\"inferSchema\",true).load(\"/user/maria_dev/final/IowaCity/IowaCityWeather.csv\"\n    ).filter($\"TemperatureF\" > -100 ).select(\"Year\", \"Month\", \"Day\",\"TimeCST\", \"TemperatureF\")\n\nval extraW = weatherW.withColumn(\"dateString\", \n    concat($\"Year\", lit(\"-\"), format_string(\"%02d\", $\"Month\"), lit(\"-\"), format_string(\"%02d\", $\"Day\"), lit(\" \"), $\"TimeCST\"  )\n    ).withColumn(\"totalSeconds\", \n    unix_timestamp($\"dateString\", \"yyyy-MM-dd h:mm a\")\n    ).withColumn(\"Hour\", \n    from_unixtime($\"totalSeconds\",\"HH\") cast \"Int\"\n    )\n\nval extraI = weatherI.withColumn(\"dateString\", \n    concat($\"Year\", lit(\"-\"), format_string(\"%02d\", $\"Month\"), lit(\"-\"), format_string(\"%02d\", $\"Day\"), lit(\" \"), $\"TimeCST\"  )\n    ).withColumn(\"totalSeconds\", \n    unix_timestamp($\"dateString\", \"yyyy-MM-dd h:mm a\")\n    ).withColumn(\"Hour\", \n    from_unixtime($\"totalSeconds\",\"HH\") cast \"Int\"\n    )\n\nval windowSpec = Window.orderBy(\"totalSeconds\").rangeBetween(0,60*60*24-1)\nval windowSpec2 = Window.orderBy($\"mean_temp\".desc)\n\nval extraW2 = extraW.withColumn(\"min_temp\", min(extraW(\"TemperatureF\")).over(windowSpec)\n).withColumn(\"max_temp\", max(extraW(\"TemperatureF\")).over(windowSpec)\n).withColumn(\"temp_diff\", $\"max_temp\" - $\"min_temp\")\n\nval extraI2 = extraI.withColumn(\"min_temp\", min(extraI(\"TemperatureF\")).over(windowSpec)\n).withColumn(\"max_temp\", max(extraI(\"TemperatureF\")).over(windowSpec)\n).withColumn(\"temp_diff\", $\"max_temp\" - $\"min_temp\")\n\n\nval answerW = extraW2.orderBy($\"temp_diff\".desc).limit(1)\nanswerW.show(false)\nval secondsW24 = answerW.select(\"totalSeconds\").map(r => r.getLong(0)).collect.toList\nval answerW2 = extraW2.filter($\"totalSeconds\" >= secondsW24(0) && $\"totalSeconds\" <= secondsW24(0) + 60*60*24-1).orderBy(\"totalSeconds\")\n// Note: Manually enter temperature found in answerW\nval answerW3 = answerW2.filter($\"TemperatureF\" === 39.2 || $\"TemperatureF\" === -11.9)\nanswerW3.show(50, false)\n\n\nval answerI = extraI2.orderBy($\"temp_diff\".desc).limit(1)\nanswerI.show(false)\nval secondsI24 = answerI.select(\"totalSeconds\").map(r => r.getLong(0)).collect.toList\nval answerI2 = extraI2.filter($\"totalSeconds\" >= secondsI24(0) && $\"totalSeconds\" <= secondsI24(0) + 60*60*24-1).orderBy(\"totalSeconds\")\n// Note: Manually enter temperature found in answerI\nval answerI3 = answerI2.filter($\"TemperatureF\" === 57.2 || $\"TemperatureF\" === 1.0)\nanswerI3.show(50, false)\n\n","user":"anonymous","dateUpdated":"2020-12-16T01:51:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions._\nweatherW: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 3 more fields]\nweatherI: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 3 more fields]\nextraW: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 6 more fields]\nextraI: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 6 more fields]\nwindowSpec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@fe768c2\nwindowSpec2: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@1db3fcc7\nextraW2: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 9 more fields]\nextraI2: org.apache.spark.sql.DataFrame = [Year: int, Month: int ... 9 more fields]\nanswerW: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|Year|Month|Day|TimeCST|TemperatureF|dateString        |totalSeconds|Hour|min_temp|max_temp|temp_diff|\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|2008|1    |29 |6:53 AM|37.9        |2008-01-29 6:53 AM|1201589580  |6   |-11.9   |39.2    |51.1     |\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n\nsecondsW24: List[Long] = List(1201589580)\nanswerW2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\nanswerW3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|Year|Month|Day|TimeCST|TemperatureF|dateString        |totalSeconds|Hour|min_temp|max_temp|temp_diff|\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|2008|1    |29 |8:29 AM|39.2        |2008-01-29 8:29 AM|1201595340  |8   |-11.9   |39.2    |51.1     |\n|2008|1    |30 |5:53 AM|-11.9       |2008-01-30 5:53 AM|1201672380  |5   |-11.9   |1.9     |13.8     |\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n\nanswerI: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|Year|Month|Day|TimeCST|TemperatureF|dateString        |totalSeconds|Hour|min_temp|max_temp|temp_diff|\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n|2008|12   |14 |7:19 AM|46.4        |2008-12-14 7:19 AM|1229239140  |7   |1.0     |57.2    |56.2     |\n+----+-----+---+-------+------------+------------------+------------+----+--------+--------+---------+\n\nsecondsI24: List[Long] = List(1229239140)\nanswerI2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\nanswerI3: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 9 more fields]\n+----+-----+---+--------+------------+-------------------+------------+----+--------+--------+---------+\n|Year|Month|Day|TimeCST |TemperatureF|dateString         |totalSeconds|Hour|min_temp|max_temp|temp_diff|\n+----+-----+---+--------+------------+-------------------+------------+----+--------+--------+---------+\n|2008|12   |14 |12:29 PM|57.2        |2008-12-14 12:29 PM|1229257740  |12  |1.0     |57.2    |56.2     |\n|2008|12   |15 |6:52 AM |1.0         |2008-12-15 6:52 AM |1229323920  |6   |1.0     |9.0     |8.0      |\n+----+-----+---+--------+------------+-------------------+------------+----+--------+--------+---------+\n\n"}]},"apps":[],"jobName":"paragraph_1608074684216_2026667657","id":"20201215-232444_534669131","dateCreated":"2020-12-15T23:24:44+0000","dateStarted":"2020-12-16T01:51:28+0000","dateFinished":"2020-12-16T01:52:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:13860"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1608074778874_-807084613","id":"20201215-232618_1900259852","dateCreated":"2020-12-15T23:26:18+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:13861"}],"name":"prob1e","id":"2FS8NBK5A","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}